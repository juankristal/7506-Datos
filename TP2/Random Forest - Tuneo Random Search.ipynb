{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import common.common_machine_learning as common\n",
    "\n",
    "#pd.set_option('display.float_format', lambda x: '%.0f' % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluar_rf(modelo, X_test, y_test):\n",
    "    y_pred = modelo.predict(X_test)\n",
    "    errors = abs(y_pred - y_test)\n",
    "    mape = 100 * np.mean(errors / y_test)\n",
    "    accuracy = 100 - mape\n",
    "    print('Performance del modelo:')\n",
    "    print('Average Error: {:0.4f} degrees.'.format(np.mean(errors)))\n",
    "    print('Accuracy = {:0.2f}%.'.format(accuracy))\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_ITER = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limpieza de datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elijo columnas basándome en la importancia según Univariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = 'precio'\n",
    "columnas = [\"tipodepropiedad\", \"provincia\", \"antiguedad\", \"metroscubiertos\",\n",
    "           \"metrostotales\", \"gimnasio\", \"usosmultiples\", \"piscina\", \"escuelascercanas\", \"centroscomercialescercanos\", \"precio\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('sets_de_datos/train.csv', index_col = 0)\n",
    "test = pd.read_csv('sets_de_datos/test.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limpio el set train: elimino columnas con nans, relleno con promedios, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[columnas]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tipodepropiedad                  46\n",
       "provincia                       155\n",
       "antiguedad                    43555\n",
       "metroscubiertos               17400\n",
       "metrostotales                 51467\n",
       "gimnasio                          0\n",
       "usosmultiples                     0\n",
       "piscina                           0\n",
       "escuelascercanas                  0\n",
       "centroscomercialescercanos        0\n",
       "precio                            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"antiguedad\"].fillna(train[\"antiguedad\"].mean(),inplace=True)\n",
    "train[\"metroscubiertos\"].fillna(train[\"metroscubiertos\"].mean(), inplace=True)\n",
    "train[\"metrostotales\"].fillna(train[\"metrostotales\"].mean(), inplace=True)\n",
    "train[\"precio\"].fillna(train[\"precio\"].mean(), inplace=True)\n",
    "train.dropna(subset=[\"tipodepropiedad\"], inplace=True)\n",
    "train.fillna(0, inplace=True)\n",
    "\n",
    "#filtro la que no están en test para que train y test tengan las mismas columnas tras el encoding\n",
    "train[\"tipodepropiedad\"] = train[train[\"tipodepropiedad\"].isin(test[\"tipodepropiedad\"].unique())]\n",
    "train.dropna(subset=[\"tipodepropiedad\"], inplace=True)\n",
    "train['provincia'] = train['provincia'].str.replace(\"provincia_0\",\"nan\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tipodepropiedad                 0\n",
       "provincia                     153\n",
       "antiguedad                      0\n",
       "metroscubiertos                 0\n",
       "metrostotales                   0\n",
       "gimnasio                        0\n",
       "usosmultiples                   0\n",
       "piscina                         0\n",
       "escuelascercanas                0\n",
       "centroscomercialescercanos      0\n",
       "precio                          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limpio el set test: relleno con promedios y moda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas_test = [\"tipodepropiedad\", \"provincia\", \"antiguedad\", \"metroscubiertos\",\n",
    "                 \"metrostotales\", \"gimnasio\", \"usosmultiples\", \"piscina\", \"escuelascercanas\", \"centroscomercialescercanos\"]\n",
    "test = test[columnas_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tipodepropiedad                   7\n",
       "provincia                        42\n",
       "antiguedad                    10714\n",
       "metroscubiertos                4299\n",
       "metrostotales                 12655\n",
       "gimnasio                          0\n",
       "usosmultiples                     0\n",
       "piscina                           0\n",
       "escuelascercanas                  0\n",
       "centroscomercialescercanos        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ciudad = test[\"ciudad\"].mode()\n",
    "#tipodepropiedad = test[\"tipodepropiedad\"].mode()\n",
    "\n",
    "test = test.fillna(value = {'tipodepropiedad' : test[\"tipodepropiedad\"].mode().to_string(),\n",
    "                            'provincia' : test[\"provincia\"].mode().to_string()})\n",
    "#test[\"tipodepropiedad\"].fillna(test[\"ciudad\"].mode(), inplace=True)\n",
    "#est[\"ciudad\"].fillna(test[\"ciudad\"].mode(), inplace=True)\n",
    "test[\"antiguedad\"].fillna(test[\"antiguedad\"].mean(), inplace=True)\n",
    "test[\"metroscubiertos\"].fillna(test[\"metroscubiertos\"].mean(), inplace=True)\n",
    "test[\"metrostotales\"].fillna(test[\"metrostotales\"].mean(), inplace=True)\n",
    "\n",
    "test['provincia'] = test['provincia'].str.replace('0    Distrito Federal','Distrito Federal') #Sino, explota el universo >:[\n",
    "test['tipodepropiedad'] = test['tipodepropiedad'].str.replace('0    Casa',\"Casa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tipodepropiedad               0\n",
       "provincia                     0\n",
       "antiguedad                    0\n",
       "metroscubiertos               0\n",
       "metrostotales                 0\n",
       "gimnasio                      0\n",
       "usosmultiples                 0\n",
       "piscina                       0\n",
       "escuelascercanas              0\n",
       "centroscomercialescercanos    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hot Encoding para train y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_OHE  = pd.get_dummies(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_OHE = pd.get_dummies(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divido train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_OHE.drop([TARGET], axis = 1).copy().values\n",
    "y = list(train_OHE[TARGET].copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hiperparámetros a tunear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "hiperparametros = {\n",
    "    \"n_estimators\": [100, 200, 250 ,300, 350 ,400, 500],\n",
    "    \"max_depth\": [10, 20, 30, 40, 50, 60],\n",
    "    \"max_features\": [1, 5, 'auto', 'sqrt', 'log2'],\n",
    "    \"min_samples_leaf\": [1, 2, 4],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuneo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed: 30.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise-deprecating',\n",
       "                   estimator=RandomForestRegressor(bootstrap=True,\n",
       "                                                   criterion='mse',\n",
       "                                                   max_depth=None,\n",
       "                                                   max_features='auto',\n",
       "                                                   max_leaf_nodes=None,\n",
       "                                                   min_impurity_decrease=0.0,\n",
       "                                                   min_impurity_split=None,\n",
       "                                                   min_samples_leaf=1,\n",
       "                                                   min_samples_split=2,\n",
       "                                                   min_weight_fraction_leaf=0.0,\n",
       "                                                   n_estimators='warn',\n",
       "                                                   n_jobs=None, oob_score=False,\n",
       "                                                   random_sta...se=0,\n",
       "                                                   warm_start=False),\n",
       "                   iid='warn', n_iter=10, n_jobs=-1,\n",
       "                   param_distributions={'max_depth': [10, 20, 30, 40, 50, 60],\n",
       "                                        'max_features': [1, 5, 'auto', 'sqrt',\n",
       "                                                         'log2'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [100, 200, 250, 300,\n",
       "                                                         350, 400, 500]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=2)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestRegressor()\n",
    "\n",
    "inicio = time.time()\n",
    "\n",
    "\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = hiperparametros, n_iter = MAX_ITER, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "\n",
    "fin = time.time()\n",
    "\n",
    "rf_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El tuneo tardó: 0.0 minutos.\n"
     ]
    }
   ],
   "source": [
    "print(\"El tuneo tardó: {} minutos.\".format((fin - inicio) / 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parámetros:\n",
      "{'n_estimators': 300, 'min_samples_split': 10, 'min_samples_leaf': 4, 'max_features': 'auto', 'max_depth': 40}\n"
     ]
    }
   ],
   "source": [
    "print(\"Mejores parámetros:\")\n",
    "print(rf_random.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "mejores_hiperparametros = rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=40,\n",
       "                      max_features='auto', max_leaf_nodes=None,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=4, min_samples_split=10,\n",
       "                      min_weight_fraction_leaf=0.0, n_estimators=300,\n",
       "                      n_jobs=None, oob_score=False, random_state=None,\n",
       "                      verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mejor_rf = RandomForestRegressor(n_estimators = mejores_hiperparametros[\"n_estimators\"],\n",
    "                                 min_samples_split = mejores_hiperparametros[\"min_samples_split\"],\n",
    "                                 min_samples_leaf = mejores_hiperparametros[\"min_samples_leaf\"],\n",
    "                                 max_features = mejores_hiperparametros[\"max_features\"],\n",
    "                                 max_depth = mejores_hiperparametros[\"max_depth\"])\n",
    "mejor_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance del modelo:\n",
      "Average Error: 730152.3149 degrees.\n",
      "Accuracy = 64.68%.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "64.67709726761025"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluar_rf(mejor_rf, X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
