{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Tomando en cuenta las conclusiones de Tuneo_XGB_A tomo las siguientes consideraciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_importancia_1 = [\"ciudad\", \"metroscubiertos\", \"metrostotales\"]\n",
    "col_importancia_2 = [\"fecha_n\", \"provincia\", \"tipodepropiedad\", \"antiguedad\"]\n",
    "col_importancia_3 = [\"habitaciones\", \"banos\", \"garages\"]\n",
    "col_importancia_4 = [\"piscina\", \"gimnasio\", \"escuelascercanas\", \"centroscomercialescercanos\", \"usosmultiples\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Voy a usar los siguientes encoders:\n",
    "    -TargetEncoder\n",
    "    -One hot encoder (para los mas importantes)\n",
    "    -Count Encoding\n",
    "    -CatBoost Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from category_encoders import TargetEncoder, CountEncoder, CatBoostEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_encoding(datos, precio, cols):\n",
    "    codificador = TargetEncoder(cols=cols)\n",
    "    return codificador.fit_transform(datos, precio)\n",
    "\n",
    "def one_hot_encoding(datos, precio, feature_ohe, features):\n",
    "    #No hago one hot de todo porque queda muy grande el dataframe\n",
    "    df_ohe = datos[feature_ohe]\n",
    "    df_1 = datos.drop(feature_ohe, axis=1)\n",
    "    df_ohe = pd.get_dummies(df_ohe)\n",
    "    \n",
    "    df_1 = target_encoding(df_1, precio, features)\n",
    "    \n",
    "    df_respuesta = df_1.join(df_ohe)\n",
    "    return df_respuesta\n",
    "\n",
    "def count_encoding(df, col_categ, col_datos):\n",
    "    codificador = CountEncoder()\n",
    "    cod = codificador.fit_transform(df[col_categ])\n",
    "    return df[col_datos].join(cod.add_suffix(\"_count\"))\n",
    "    \n",
    "def catboost_encoding(datos, precio, cols):\n",
    "    codificador = CatBoostEncoder(cols=cols)\n",
    "    return codificador.fit_transform(datos, precio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Voy a dar la opcion de eliminar o no los features de importancia 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eliminar_imp_3(df):\n",
    "    return df.drop(col_importancia_3, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparo el dataframe para tunear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Hacer de esto una funcion o guardarlo hecho como CSV\n",
    "#Levanto el df\n",
    "train = pd.read_csv(\"sets_de_datos/train.csv\", index_col=0)\n",
    "\n",
    "#Convierto la fecha a numero\n",
    "train[\"fecha\"] = pd.to_datetime(train[\"fecha\"])\n",
    "train[\"fecha_n\"] = train[\"fecha\"].dt.year * 10000 + train[\"fecha\"].dt.month * 100 + train[\"fecha\"].dt.day\n",
    "\n",
    "#Borro columnas\n",
    "col_borrar = [\"direccion\", \"lat\", \"lng\", \"titulo\", \"descripcion\", \"idzona\", \"fecha\"]\n",
    "train_1 = train.drop(col_borrar, axis=1)\n",
    "\n",
    "#Borro las columnas de menor importancia\n",
    "train_1 = train_1.drop(col_importancia_4, axis=1)\n",
    "\n",
    "#Imputo los nans\n",
    "train_1 = train_1.fillna(value = {'tipodepropiedad' : 'nan', 'provincia' : 'nan', 'ciudad' : 'nan'})\n",
    "\n",
    "for c in [\"antiguedad\", \"metrostotales\", \"metroscubiertos\"]:\n",
    "    imputer = SimpleImputer(strategy=\"mean\")\n",
    "    train_1[c] = imputer.fit_transform(train_1[[c]])\n",
    "\n",
    "for c in [\"habitaciones\", \"banos\", \"garages\"]:\n",
    "    imputer = SimpleImputer(strategy=\"constant\", fill_value=0)\n",
    "    train_1[c] = imputer.fit_transform(train_1[[c]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos = train_1.drop([\"precio\"], axis=1)\n",
    "precio = train_1[\"precio\"]\n",
    "\n",
    "COL_CATEGORICAS = [\"provincia\", \"ciudad\", \"tipodepropiedad\"]\n",
    "def col_no_categoricos(df):\n",
    "    return df.dtypes[df.dtypes != \"object\"].index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creo el espacio de tuneo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Constantes del espacio de tuneo\n",
    "TARGET = 0\n",
    "OHE = 1\n",
    "COUNT = 2\n",
    "CATBOOST = 3\n",
    "\n",
    "ELIMINAR_IMP_3 = 0\n",
    "NO_ELIMINAR_IMP_3 = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "espacio_xgb = {\n",
    "    \"objective\" : \"reg:squarederror\",\n",
    "    \"encoder\" : hp.choice(\"encoder\", [TARGET, OHE, COUNT, CATBOOST]),\n",
    "    \"importancia_3\" : hp.choice(\"importancia_3\", [ELIMINAR_IMP_3, NO_ELIMINAR_IMP_3]),\n",
    "    \"n_estimators\" : hp.choice(\"n_estimators\", range(1000, 2001)),\n",
    "    \"min_child_weight\" : hp.choice(\"min_child_weight\", range(1,6)),\n",
    "    \"max_depth\" : hp.choice(\"max_depth\", range(8, 16)),\n",
    "    \"learning_rate\" : hp.uniform(\"learning_rate\", 0.01, 0.1),\n",
    "    \"reg_lambda\" : hp.uniform(\"reg_lambda\", 0.03, 0.3),\n",
    "    \"gamma\" : hp.uniform(\"gamma\", 0, 0.5),\n",
    "    \"colsample_bytree\" : hp.uniform(\"colsample_bytree\", 0.5, 1),\n",
    "    \"subsample\" : hp.uniform(\"subsample\", 0.5, 1)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Funcion del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from xgboost import XGBRegressor\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperopt_train_test(params, datos, precio):\n",
    "    datos_ = datos\n",
    "    #================FEATURES===================\n",
    "    if params[\"importancia_3\"] == ELIMINAR_IMP_3:\n",
    "        datos_ = eliminar_imp_3(datos_)\n",
    "    \n",
    "    #===============ENCODING============\n",
    "    if params[\"encoder\"] == TARGET:\n",
    "        datos_ = target_encoding(datos_, precio, COL_CATEGORICAS)\n",
    "        \n",
    "    if params[\"encoder\"] == OHE:\n",
    "        datos_ = one_hot_encoding(datos_, precio, [\"ciudad\"], [\"tipodepropiedad\", \"provincia\"])\n",
    "        \n",
    "    if params[\"encoder\"] == COUNT:\n",
    "        datos_ = count_encoding(datos_, COL_CATEGORICAS, col_no_categoricos(datos_))\n",
    "        \n",
    "    if params[\"encoder\"] == CATBOOST:\n",
    "        datos_ = catboost_encoding(datos_, precio, COL_CATEGORICAS)\n",
    "    \n",
    "    \n",
    "    modelo = XGBRegressor(**params)\n",
    "    return cross_val_score(modelo, datos_, precio).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(params):\n",
    "    acc = hyperopt_train_test(params, datos, precio)\n",
    "    return {'loss': -acc, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tuneo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from warnings import simplefilter\n",
    "simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = Trials()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [34:09<00:00, 1024.54s/it, best loss: -0.7965954181618882]\n"
     ]
    }
   ],
   "source": [
    "best = fmin(f, espacio_xgb, algo=tpe.suggest, max_evals=2, trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.5522426459530355,\n",
       " 'encoder': 0,\n",
       " 'gamma': 0.049417927153982966,\n",
       " 'importancia_3': 1,\n",
       " 'learning_rate': 0.028491939247932148,\n",
       " 'max_depth': 3,\n",
       " 'min_child_weight': 0,\n",
       " 'n_estimators': 926,\n",
       " 'reg_lambda': 0.18106491312186662,\n",
       " 'subsample': 0.7925982324384148}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hice un ejemplo con 2 evaluaciones de juguete, uno mas grande me daba problemas de memoria\n",
    "#corri uno un poco mas grande con google colab"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
